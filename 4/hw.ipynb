{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import random\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#отключает warnings pytorch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEVICE_ID = 2\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Для запуска без GPU раскомментировать и закоментировать код выше\n",
    "# DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(100500)\n",
    "\n",
    "def data2image(data):\n",
    "    res = np.transpose(np.reshape(data ,(3, 32,32)), (1,2,0))\n",
    "    return PIL.Image.fromarray(np.uint8(res))\n",
    "\n",
    "def imshow(img):\n",
    "    if isinstance(img, torch.Tensor): img = img.numpy().astype('uint8')\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "def prediction2classes(output_var):\n",
    "    _, predicted = torch.max(output_var.data, 1)\n",
    "    predicted.squeeze_()\n",
    "    classes = predicted.tolist()\n",
    "    return classes\n",
    "\n",
    "def make_solution_pytorch(net, input_tensor, a_batch_size):\n",
    "    res = []\n",
    "    net = net.eval()\n",
    "    cur_pos = 0\n",
    "    while cur_pos <= len(input_tensor):\n",
    "        outputs = net(input_tensor[cur_pos:cur_pos+a_batch_size])\n",
    "        res += prediction2classes(outputs)\n",
    "        cur_pos += a_batch_size\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, input_path, is_train=True, transform=None):\n",
    "                        \n",
    "        data = np.load(input_path)\n",
    "        if is_train: \n",
    "            self.Y, self.X = np.hsplit(data, [1]) \n",
    "            self.Y = [item[0] for item in self.Y]\n",
    "        else: \n",
    "            self.X = data\n",
    "            self.Y = None\n",
    "            \n",
    "        self.X = self.X.reshape((self.X.shape[0], 3, 32, 32))\n",
    "        self.X = self.X.transpose((0, 2, 3, 1)) #приводим к виду (N, H, W, C)\n",
    "        self.X = [Image.fromarray(img) for img in self.X]\n",
    "                \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.X[idx]\n",
    "\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "\n",
    "        if self.Y is None: return sample\n",
    "        else: return (sample, self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Надо поменять пути на свои до файлов с kaggle\n",
    "DATA_PATH  = '/home/alexander.veselev/'\n",
    "train_path = 'homework_4.train.npy'\n",
    "test_path  = 'homework_4_no_classes.test.npy'\n",
    "saved_net_path = 'saved_net.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_mean = np.mean([item[0].numpy() for item in CifarDataset(DATA_PATH + train_path, transform=transforms.ToTensor())], axis=(0,2,3))\n",
    "np_std = np.std([item[0].numpy() for item in CifarDataset(DATA_PATH + train_path, transform=transforms.ToTensor())], axis=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_transform_norm = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")\n",
    "\n",
    "cifar_test_transform_norm = transforms.Compose([    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "dataset_train_norm = CifarDataset(DATA_PATH + train_path, transform=cifar_transform_norm)\n",
    "dataloader_train_norm = DataLoader(dataset_train_norm, batch_size=128,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_test_norm = CifarDataset(DATA_PATH + test_path, is_train=False, transform=cifar_test_transform_norm)\n",
    "dataloader_test_norm = DataLoader(dataset_test_norm, batch_size=128,\n",
    "                        shuffle=False, num_workers=1)\n",
    "saved_net_path = 'net_saved.pth'\n",
    "\n",
    "def train_network(a_net, \n",
    "                  a_device,\n",
    "                  dataloader_train_norm=dataloader_train_norm,\n",
    "                  a_epochs=164,\n",
    "                  a_batch_size=128,\n",
    "                  a_lr=0.1):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_acc = []\n",
    "    net = a_net.to(a_device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "    prev_epoch_time = start_time\n",
    "    for epoch in range(a_epochs):  # loop over the dataset multiple times\n",
    "        if epoch == 42:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/10, weight_decay=0.0001, momentum=0.9) \n",
    "        elif epoch == 90:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/100, weight_decay=0.0001, momentum=0.9) \n",
    "        elif epoch == 123:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/250, weight_decay=0.0001, momentum=0.9)\n",
    "         \n",
    "        net = net.train()        \n",
    "        epoch_accuracy = 0.0\n",
    "        epoch_iters = 0\n",
    "        for item in dataloader_train_norm:\n",
    "            \n",
    "            epoch_iters += 1\n",
    "\n",
    "            inputs = item[0].to(a_device)\n",
    "            labels = item[1].long().to(a_device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_accuracy += accuracy_score(labels.cpu(), prediction2classes(outputs))\n",
    "\n",
    "        epoch_accuracy /= epoch_iters\n",
    "        train_acc.append(epoch_accuracy)\n",
    "\n",
    "        # saving the net state\n",
    "        torch.save(net.state_dict(), DATA_PATH + saved_net_path)\n",
    "        print(\"Epoch {}\\t Train accuracy {}\".format(epoch, round(train_acc[-1], 4)))\n",
    "        cur_epoch_time = time.time()\n",
    "        print('Epoch time : ', cur_epoch_time - prev_epoch_time )\n",
    "        prev_epoch_time = cur_epoch_time\n",
    "        \n",
    "    print('Finished Training')\n",
    "    print(\"Total time : \", (time.time()-start_time))\n",
    "    \n",
    "    plt.plot(train_acc, label='Train')\n",
    "    plt.legend()\n",
    "    plt.grid(c='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOWNSAMPLE_COEF = 2\n",
    "\n",
    "def conv3x3(a_in_planes, a_out_planes, a_stride=1):\n",
    "    \"\"\"\n",
    "    Основной строительный блок конволюций для ResNet\n",
    "    Включает в себя padding=1 - чтобы размерность сохранялась после его применения\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(a_in_planes, a_out_planes,  stride=a_stride,\n",
    "                     kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "def x_downsample(a_in_channels, a_out_channels, stride):\n",
    "     return nn.Conv2d(a_in_channels, \n",
    "               a_out_channels,\n",
    "               kernel_size=1,\n",
    "               stride=stride,\n",
    "               bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CifarResidualBlock(nn.Module):\n",
    "    def __init__(self, a_in_channels, \n",
    "                       a_out_channels, \n",
    "                       stride=1,\n",
    "                       make_downsample=False):\n",
    "        super(CifarResidualBlock, self).__init__()\n",
    "        self.make_downsample = make_downsample\n",
    "        \n",
    "        self.features = nn.Sequential()\n",
    "        self.features.add_module('conv_1', conv3x3(a_in_channels, \n",
    "                                                   a_out_channels))\n",
    "        self.features.add_module('bn_1', nn.BatchNorm2d(a_out_channels))\n",
    "        self.features.add_module('relu_1', nn.ReLU())\n",
    "        self.features.add_module('conv_2', conv3x3(a_out_channels, \n",
    "                                                   a_out_channels, \n",
    "                                                   a_stride=stride))\n",
    "        self.features.add_module('bn_2', nn.BatchNorm2d(a_out_channels))\n",
    "        self.features.add_module('relu_2', nn.ReLU())\n",
    "        \n",
    "        \n",
    "        self.downsample =  nn.Sequential()\n",
    "        if self.make_downsample:\n",
    "            self.downsample = nn.Sequential(\n",
    "                                     x_downsample(a_in_channels, \n",
    "                                                  a_out_channels, \n",
    "                                                  stride)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        net = self.features(x)\n",
    "        net += self.downsample(x)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CifarResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CifarResNet, self).__init__()        \n",
    "        \n",
    "        self.features = nn.Sequential()\n",
    "        self.features.add_module('conv_1', conv3x3(3, 16))\n",
    "        self.features.add_module('bn_1', nn.BatchNorm2d(16))\n",
    "        self.features.add_module('relu_1', nn.LeakyReLU())\n",
    "        self.features.add_module('cifar_1', \n",
    "                                 CifarResidualBlock(16, 64, \n",
    "                                                    make_downsample=True))\n",
    "        self.features.add_module('cifar_2', \n",
    "                                 CifarResidualBlock(64, 64))\n",
    "        self.features.add_module('dropout_1', \n",
    "                                 nn.Dropout(p=0.2))\n",
    "        self.features.add_module('cifar_3', \n",
    "                                 CifarResidualBlock(64, 64))\n",
    "        self.features.add_module('cifar_4', \n",
    "                                 CifarResidualBlock(64, 128, stride=2,\n",
    "                                                    make_downsample=True))\n",
    "        self.features.add_module('cifar_5', \n",
    "                                 CifarResidualBlock(128, 128))\n",
    "        self.features.add_module('dropout_2', \n",
    "                                 nn.Dropout(p=0.2))\n",
    "        self.features.add_module('cifar_6', \n",
    "                                 CifarResidualBlock(128, 128))\n",
    "        self.features.add_module('cifar_7', \n",
    "                                 CifarResidualBlock(128, 256, stride=2,\n",
    "                                                    make_downsample=True))\n",
    "        self.features.add_module('cifar_8', \n",
    "                                 CifarResidualBlock(256, 256))\n",
    "        self.features.add_module('dropout_3', \n",
    "                                 nn.Dropout(p=0.2))\n",
    "        self.features.add_module('cifar_9', \n",
    "                                 CifarResidualBlock(256, 256))\n",
    "        self.features.add_module('cifar_10', \n",
    "                                 CifarResidualBlock(256, 512, stride=2,\n",
    "                                                    make_downsample=True))\n",
    "\n",
    "        self.global_avg_pooling = nn.AvgPool2d(kernel_size=8)\n",
    "        self.fc_classifier = nn.Linear(512, 100)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_avg_pooling(x)        \n",
    "        x = x.view((x.size()[0], -1))        \n",
    "        x = self.fc_classifier(x)        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\t Train accuracy 0.1024\n",
      "Epoch time :  41.11146354675293\n",
      "Epoch 1\t Train accuracy 0.2172\n",
      "Epoch time :  41.813024282455444\n",
      "Epoch 2\t Train accuracy 0.3115\n",
      "Epoch time :  42.263654947280884\n",
      "Epoch 3\t Train accuracy 0.3837\n",
      "Epoch time :  43.07895469665527\n",
      "Epoch 4\t Train accuracy 0.4411\n",
      "Epoch time :  43.346132040023804\n",
      "Epoch 5\t Train accuracy 0.4862\n",
      "Epoch time :  43.16741943359375\n",
      "Epoch 6\t Train accuracy 0.5179\n",
      "Epoch time :  43.32621121406555\n",
      "Epoch 7\t Train accuracy 0.5515\n",
      "Epoch time :  43.48669672012329\n",
      "Epoch 8\t Train accuracy 0.572\n",
      "Epoch time :  43.518646478652954\n",
      "Epoch 9\t Train accuracy 0.5998\n",
      "Epoch time :  43.36449098587036\n",
      "Epoch 10\t Train accuracy 0.6192\n",
      "Epoch time :  43.49647259712219\n",
      "Epoch 11\t Train accuracy 0.6358\n",
      "Epoch time :  43.49483895301819\n",
      "Epoch 12\t Train accuracy 0.6479\n",
      "Epoch time :  43.43880867958069\n",
      "Epoch 13\t Train accuracy 0.6647\n",
      "Epoch time :  43.34212684631348\n",
      "Epoch 14\t Train accuracy 0.674\n",
      "Epoch time :  43.382230043411255\n",
      "Epoch 15\t Train accuracy 0.6862\n",
      "Epoch time :  43.27711629867554\n",
      "Epoch 16\t Train accuracy 0.6956\n",
      "Epoch time :  43.279526233673096\n",
      "Epoch 17\t Train accuracy 0.7068\n",
      "Epoch time :  43.54237222671509\n",
      "Epoch 18\t Train accuracy 0.7134\n",
      "Epoch time :  43.44389295578003\n",
      "Epoch 19\t Train accuracy 0.725\n",
      "Epoch time :  43.59258961677551\n",
      "Epoch 20\t Train accuracy 0.7345\n",
      "Epoch time :  43.31738519668579\n",
      "Epoch 21\t Train accuracy 0.738\n",
      "Epoch time :  43.25743746757507\n",
      "Epoch 22\t Train accuracy 0.7464\n",
      "Epoch time :  43.21497917175293\n",
      "Epoch 23\t Train accuracy 0.7552\n",
      "Epoch time :  43.72663116455078\n",
      "Epoch 24\t Train accuracy 0.7614\n",
      "Epoch time :  43.25201344490051\n",
      "Epoch 25\t Train accuracy 0.7691\n",
      "Epoch time :  43.188445806503296\n",
      "Epoch 26\t Train accuracy 0.7712\n",
      "Epoch time :  43.206090450286865\n",
      "Epoch 27\t Train accuracy 0.7785\n",
      "Epoch time :  43.463908195495605\n",
      "Epoch 28\t Train accuracy 0.779\n",
      "Epoch time :  43.1430881023407\n",
      "Epoch 29\t Train accuracy 0.7867\n",
      "Epoch time :  43.24136471748352\n",
      "Epoch 30\t Train accuracy 0.7912\n",
      "Epoch time :  43.37026810646057\n",
      "Epoch 31\t Train accuracy 0.7938\n",
      "Epoch time :  43.299084424972534\n",
      "Epoch 32\t Train accuracy 0.8009\n",
      "Epoch time :  43.279589891433716\n",
      "Epoch 33\t Train accuracy 0.8067\n",
      "Epoch time :  43.32260727882385\n",
      "Epoch 34\t Train accuracy 0.8096\n",
      "Epoch time :  43.38830757141113\n",
      "Epoch 35\t Train accuracy 0.8103\n",
      "Epoch time :  43.259156227111816\n",
      "Epoch 36\t Train accuracy 0.8135\n",
      "Epoch time :  43.52183938026428\n",
      "Epoch 37\t Train accuracy 0.8165\n",
      "Epoch time :  43.39319348335266\n",
      "Epoch 38\t Train accuracy 0.8197\n",
      "Epoch time :  43.481480836868286\n",
      "Epoch 39\t Train accuracy 0.8237\n",
      "Epoch time :  43.58085751533508\n",
      "Epoch 40\t Train accuracy 0.8265\n",
      "Epoch time :  43.14214849472046\n",
      "Epoch 41\t Train accuracy 0.8326\n",
      "Epoch time :  43.45016956329346\n",
      "Epoch 42\t Train accuracy 0.9188\n",
      "Epoch time :  43.329344749450684\n",
      "Epoch 43\t Train accuracy 0.9489\n",
      "Epoch time :  43.53605079650879\n",
      "Epoch 44\t Train accuracy 0.9587\n",
      "Epoch time :  43.62057065963745\n",
      "Epoch 45\t Train accuracy 0.9655\n",
      "Epoch time :  43.20199966430664\n",
      "Epoch 46\t Train accuracy 0.9701\n",
      "Epoch time :  43.45183181762695\n",
      "Epoch 47\t Train accuracy 0.9721\n",
      "Epoch time :  43.465564012527466\n",
      "Epoch 48\t Train accuracy 0.9767\n",
      "Epoch time :  43.42420935630798\n",
      "Epoch 49\t Train accuracy 0.977\n",
      "Epoch time :  43.32304620742798\n",
      "Epoch 50\t Train accuracy 0.9808\n",
      "Epoch time :  43.20966863632202\n",
      "Epoch 51\t Train accuracy 0.9817\n",
      "Epoch time :  43.54595160484314\n",
      "Finished Training\n",
      "Total time :  2250.376012802124\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRMSHFO4iIj70P5VTbIb6Yml/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet = CifarResNet()\n",
    "train_network(resnet, torch.device(DEVICE), a_epochs=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Важно переключить сеть в режим eval - иначе dropout будет работать некорректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_solution(a_net, a_device):\n",
    "    res = []\n",
    "    net = a_net.eval()\n",
    "    for item in dataloader_test_norm:\n",
    "        inputs = item.to(a_device)\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        res += prediction2classes(outputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_solution = make_solution(resnet, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission.csv', 'w') as fout:\n",
    "    print('Id', 'Prediction', sep=',', file=fout)\n",
    "    for i, prediction in enumerate(my_solution):\n",
    "        print(i, prediction, sep=',', file=fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
